{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8f08b15-f3cc-4326-b5a7-b9922f1c48e5",
   "metadata": {},
   "source": [
    "\n",
    "# 📘 The Perceptron: The Simplest Neural Network\n",
    "\n",
    "The **perceptron** is the most basic type of neural network, consisting of a single neuron. It takes multiple inputs, applies corresponding weights, adds a bias, and passes the result through an activation function to produce an output.\n",
    "\n",
    "### 📐 Mathematical Representation\n",
    "\n",
    "Given inputs $ x_1, x_2, \\ldots, x_n \\), weights \\( w_1, w_2, \\ldots, w_n \\), and bias \\( b $:\n",
    "\n",
    "$$\n",
    "z = \\sum_{i=1}^{n} w_i x_i + b\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\hat{y} = \\phi(z)\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "- $ z $ is the weighted sum  \n",
    "- $ \\phi $ is the activation function  \n",
    "- $ \\hat{y} $ is the output\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## 🔧 Activation Functions\n",
    "\n",
    "### a. Sigmoid Function\n",
    "\n",
    "$$\n",
    "\\phi(z) = \\frac{1}{1 + e^{-z}}\n",
    "$$\n",
    "\n",
    "- Output range: \\( (0, 1) \\)  \n",
    "- Commonly used in binary classification\n",
    "\n",
    "### b. Tanh Function\n",
    "\n",
    "$$\n",
    "\\phi(z) = \\tanh(z) = \\frac{e^{z} - e^{-z}}{e^{z} + e^{-z}}\n",
    "$$\n",
    "\n",
    "- Output range: \\( (-1, 1) \\)  \n",
    "- Zero-centered, which can aid in optimization\n",
    "\n",
    "### c. ReLU (Rectified Linear Unit)\n",
    "\n",
    "$$\n",
    "\\phi(z) = \\max(0, z)\n",
    "$$\n",
    "\n",
    "- Output range: $\\( [0, \\infty) \\)$\n",
    "- Efficient and widely used in hidden layers\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac655faa-1a45-4fc4-9a8d-9670e586c949",
   "metadata": {},
   "source": [
    "# [Perceptron::Forward Pass] Numpy implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83cbcc77-d25e-4001-8b43-ef05881d6f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: 0.5274723043445937\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "# Inputs\n",
    "x = np.array([0.5, -0.2, 0.1])\n",
    "# Weights\n",
    "w = np.array([0.4, 0.7, -0.5])\n",
    "# Bias\n",
    "b = 0.1\n",
    "\n",
    "# Weighted sum\n",
    "z = np.dot(w, x) + b\n",
    "# Activation\n",
    "output = sigmoid(z)\n",
    "\n",
    "print(f\"Output: {output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f265984-3b9e-4a7b-8d2d-1809da37db41",
   "metadata": {},
   "source": [
    "# [Perceptron::Forward Pass] Pytorch implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f4fea9b-1d50-43cb-b605-458df60e25c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: 0.5274722576141357\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Inputs\n",
    "x = torch.tensor([0.5, -0.2, 0.1])\n",
    "# Weights\n",
    "w = torch.tensor([0.4, 0.7, -0.5])\n",
    "# Bias\n",
    "b = torch.tensor(0.1)\n",
    "\n",
    "# Weighted sum\n",
    "z = torch.dot(w, x) + b\n",
    "# Activation\n",
    "output = torch.sigmoid(z)\n",
    "\n",
    "print(f\"Output: {output.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef65fd4-2345-4fa3-8747-d2fc013ab90f",
   "metadata": {},
   "source": [
    "# [Theory] Multi-Layer Perceptron (MLP) with Backpropagation\n",
    "\n",
    "### 🔹 Forward Pass:\n",
    "\n",
    "Given input $ x \\in \\mathbb{R}^d , labels y \\in \\mathbb{R}$:\n",
    "\n",
    "#### Layer 1:\n",
    "$$\n",
    "z^{(1)} = W^{(1)} x + b^{(1)} \\\\\n",
    "a^{(1)} = \\text{ReLU}(z^{(1)})\n",
    "$$\n",
    "\n",
    "#### Layer 2:\n",
    "$$\n",
    "z^{(2)} = W^{(2)} a^{(1)} + b^{(2)} \\\\\n",
    "\\hat{y} = \\sigma(z^{(2)})\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Loss Function:\n",
    "\n",
    "Binary Cross-Entropy:\n",
    "$$\n",
    "L = - \\left[ y \\cdot \\log(\\hat{y}) + (1 - y) \\cdot \\log(1 - \\hat{y}) \\right]\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### 🔁 Backward Pass:\n",
    "\n",
    "#### Output Layer:\n",
    "$$\n",
    "\\delta^{(2)} = \\hat{y} - y \\\\\n",
    "\\frac{\\partial L}{\\partial W^{(2)}} = \\delta^{(2)} \\cdot (a^{(1)})^T \\\\\n",
    "\\frac{\\partial L}{\\partial b^{(2)}} = \\delta^{(2)}\n",
    "$$\n",
    "\n",
    "#### Hidden Layer:\n",
    "$$\n",
    "\\delta^{(1)} = (W^{(2)})^T \\delta^{(2)} \\odot \\mathbb{1}_{z^{(1)} > 0} \\\\\n",
    "\\frac{\\partial L}{\\partial W^{(1)}} = \\delta^{(1)} \\cdot x^T \\\\\n",
    "\\frac{\\partial L}{\\partial b^{(1)}} = \\delta^{(1)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c10762-9ba9-413b-bdaa-df83ed39f635",
   "metadata": {},
   "source": [
    "# MLP with One Hidden Layer\n",
    "\n",
    "We'll build:\n",
    "- 2-layer MLP\n",
    "- Input → Hidden (ReLU) → Output (Sigmoid or Linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e19fda-5f2e-469e-ac6c-9c1a60daeac8",
   "metadata": {},
   "source": [
    "## [Numpy code]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a771d854-2b47-4477-b3c1-6ee023343540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output prediction: [[0.42146409]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Activation functions\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Inputs\n",
    "X = np.array([[0.5, -0.2, 0.1]])  # (1, 3)\n",
    "# Ground truth (dummy)\n",
    "y = np.array([[1]])\n",
    "\n",
    "# Weights and biases initialization\n",
    "np.random.seed(42)\n",
    "W1 = np.random.randn(3, 4)   # Input to hidden\n",
    "b1 = np.zeros((1, 4))\n",
    "W2 = np.random.randn(4, 1)   # Hidden to output\n",
    "b2 = np.zeros((1, 1))\n",
    "\n",
    "# Forward pass\n",
    "z1 = X @ W1 + b1\n",
    "a1 = relu(z1)\n",
    "\n",
    "z2 = a1 @ W2 + b2\n",
    "a2 = sigmoid(z2)\n",
    "\n",
    "print(\"Output prediction:\", a2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de79618-05e3-40b6-a2b2-53c2ddee8d6c",
   "metadata": {},
   "source": [
    "## [PyTorch Code]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eec6303a-573e-4a86-bf89-bfe3d74176ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output prediction: 0.6412115097045898\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Input\n",
    "X = torch.tensor([[0.5, -0.2, 0.1]])\n",
    "y = torch.tensor([[1.0]])\n",
    "\n",
    "# Manual weights\n",
    "torch.manual_seed(42)\n",
    "W1 = torch.randn(3, 4, requires_grad=True)\n",
    "b1 = torch.zeros(4, requires_grad=True)\n",
    "W2 = torch.randn(4, 1, requires_grad=True)\n",
    "b2 = torch.zeros(1, requires_grad=True)\n",
    "\n",
    "# Forward pass\n",
    "z1 = X @ W1 + b1\n",
    "a1 = F.relu(z1)\n",
    "\n",
    "z2 = a1 @ W2 + b2\n",
    "a2 = torch.sigmoid(z2)\n",
    "\n",
    "print(\"Output prediction:\", a2.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f951d73-82a4-4b53-bbf0-cc6bddec6a8f",
   "metadata": {},
   "source": [
    "# 2 Layer MLP\n",
    "\n",
    "## Given:\n",
    "\n",
    "Input $x \\in \\mathbb{R}^d$, labels $y \\in \\mathbb{R}$\n",
    "\n",
    "**Network:**\n",
    "\n",
    "- **Layer 1:** $z_1 = W_1 x + b_1,\\quad a_1 = \\text{ReLU}(z_1)$  \n",
    "- **Layer 2:** $z_2 = W_2 a_1 + b_2,\\quad \\hat{y} = \\sigma(z_2)$\n",
    "\n",
    "**Loss:**\n",
    "\n",
    "$$\n",
    "L = - \\left[ y \\log(\\hat{y}) + (1 - y) \\log(1 - \\hat{y}) \\right]\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## Goal: Compute gradients w.r.t parameters:\n",
    "\n",
    "- $\\frac{\\partial L}{\\partial W_2},\\quad \\frac{\\partial L}{\\partial b_2}$\n",
    "- $\\frac{\\partial L}{\\partial W_1},\\quad \\frac{\\partial L}{\\partial b_1}$\n",
    "\n",
    "---\n",
    "\n",
    "## Derivatives:\n",
    "\n",
    "Let’s denote:\n",
    "\n",
    "$$\n",
    "\\delta_2 = \\hat{y} - y \\quad \\text{(from binary cross-entropy + sigmoid)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial W_2} = \\delta_2 \\cdot a_1^T\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\delta_1 = (W_2^T \\delta_2) \\cdot \\mathbb{1}_{z_1 > 0} \\quad \\text{(ReLU gradient)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial W_1} = \\delta_1 \\cdot x^T\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394c06d1-063f-4b67-bc19-37cfdf352747",
   "metadata": {},
   "source": [
    "## [Code] NumPy: Full Training Loop with Backprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e5f8ce2-85a6-4f7a-ae27-f29075b3e3ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 1.4788\n",
      "Epoch 100, Loss: 0.8296\n",
      "Epoch 200, Loss: 0.7299\n",
      "Epoch 300, Loss: 0.7017\n",
      "Epoch 400, Loss: 0.6898\n",
      "Epoch 500, Loss: 0.6821\n",
      "Epoch 600, Loss: 0.6789\n",
      "Epoch 700, Loss: 0.6763\n",
      "Epoch 800, Loss: 0.6742\n",
      "Epoch 900, Loss: 0.6725\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Activation + Derivatives\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def relu_derivative(x):\n",
    "    return (x > 0).astype(float)\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    s = sigmoid(x)\n",
    "    return s * (1 - s)\n",
    "\n",
    "def binary_cross_entropy(y_true, y_pred):\n",
    "    eps = 1e-8\n",
    "    return -np.mean(y_true * np.log(y_pred + eps) + (1 - y_true) * np.log(1 - y_pred + eps))\n",
    "\n",
    "# Data\n",
    "np.random.seed(42)\n",
    "X = np.random.randn(100, 3)  # 100 samples, 3 features\n",
    "y = (np.random.rand(100, 1) > 0.5).astype(float)  # Binary labels\n",
    "\n",
    "# Params\n",
    "input_size, hidden_size, output_size = 3, 4, 1\n",
    "W1 = np.random.randn(input_size, hidden_size)      # (3, 4)\n",
    "b1 = np.zeros((1, hidden_size))                    # (1, 4)\n",
    "W2 = np.random.randn(hidden_size, output_size)     # (4, 1)\n",
    "b2 = np.zeros((1, output_size))                    # (1, 1)\n",
    "\n",
    "# Training Loop\n",
    "lr = 0.01\n",
    "losses = []\n",
    "\n",
    "for epoch in range(1000):\n",
    "    # Forward\n",
    "    z1 = X @ W1 + b1      # shape: (100, 4)\n",
    "    a1 = relu(z1)         # apply ReLU to hidden layer\n",
    "    \n",
    "    z2 = a1 @ W2 + b2     # shape: (100, 1)\n",
    "    a2 = sigmoid(z2)      # predicted probabilities\n",
    "\n",
    "    # Loss\n",
    "    loss = binary_cross_entropy(y, a2)\n",
    "    losses.append(loss)\n",
    "\n",
    "    # Backward\n",
    "    delta2 = a2 - y  # (100, 1)\n",
    "    dW2 = a1.T @ delta2 / X.shape[0]  # (4, 1)\n",
    "    db2 = np.mean(delta2, axis=0, keepdims=True)  # (1, 1)\n",
    "\n",
    "    delta1 = (delta2 @ W2.T) * relu_derivative(z1)  # shape: (100, 4)\n",
    "    dW1 = X.T @ delta1 / X.shape[0]  # (3, 4)\n",
    "    db1 = np.mean(delta1, axis=0, keepdims=True)  # (1, 4)\n",
    "\n",
    "    # Update\n",
    "    W1 -= lr * dW1\n",
    "    b1 -= lr * db1\n",
    "    W2 -= lr * dW2\n",
    "    b2 -= lr * db2\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss:.4f}\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(losses)\n",
    "plt.title(\"Training Loss (NumPy MLP)\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f7f621-b6a4-4a5a-9257-31c20a060288",
   "metadata": {},
   "source": [
    "# [Code] PyTorch (no `nn` module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84c0299f-5b2d-411b-b946-22d9d32a0d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 1.0545\n",
      "Epoch 100, Loss: 0.8494\n",
      "Epoch 200, Loss: 0.7646\n",
      "Epoch 300, Loss: 0.7262\n",
      "Epoch 400, Loss: 0.7032\n",
      "Epoch 500, Loss: 0.6894\n",
      "Epoch 600, Loss: 0.6786\n",
      "Epoch 700, Loss: 0.6711\n",
      "Epoch 800, Loss: 0.6654\n",
      "Epoch 900, Loss: 0.6575\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Data\n",
    "X = torch.randn(100, 3)                # 100 samples, 3 features\n",
    "y = (torch.rand(100, 1) > 0.5).float() # Binary targets (0 or 1)\n",
    "\n",
    "# Weights and Biases (manually initialized)\n",
    "W1 = torch.randn(3, 4, requires_grad=True)  # input → hidden\n",
    "b1 = torch.zeros(4, requires_grad=True)\n",
    "\n",
    "W2 = torch.randn(4, 1, requires_grad=True)  # hidden → output\n",
    "b2 = torch.zeros(1, requires_grad=True)\n",
    "\n",
    "# Training loop\n",
    "lr = 0.01\n",
    "for epoch in range(1000):\n",
    "    # Forward pass\n",
    "    z1 = X @ W1 + b1         # shape: (100, 4)\n",
    "    a1 = F.relu(z1)          # ReLU activation\n",
    "\n",
    "    z2 = a1 @ W2 + b2        # shape: (100, 1)\n",
    "    y_pred = torch.sigmoid(z2)\n",
    "\n",
    "    # Binary Cross Entropy Loss\n",
    "    loss = F.binary_cross_entropy(y_pred, y)\n",
    "\n",
    "    # Backward\n",
    "    loss.backward()\n",
    "\n",
    "    # Gradient Descent (manual step)\n",
    "    with torch.no_grad():\n",
    "        W1 -= lr * W1.grad\n",
    "        b1 -= lr * b1.grad\n",
    "        W2 -= lr * W2.grad\n",
    "        b2 -= lr * b2.grad\n",
    "\n",
    "        # Manually zero gradients\n",
    "        W1.grad.zero_()\n",
    "        b1.grad.zero_()\n",
    "        W2.grad.zero_()\n",
    "        b2.grad.zero_()\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc5b290-580f-40d1-bb37-71629f30a06e",
   "metadata": {},
   "source": [
    "# [Code] With Autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f38a8775-61ae-4b69-9fc3-1c71fbc5659a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.6771\n",
      "Epoch 100, Loss: 0.6752\n",
      "Epoch 200, Loss: 0.6736\n",
      "Epoch 300, Loss: 0.6722\n",
      "Epoch 400, Loss: 0.6708\n",
      "Epoch 500, Loss: 0.6696\n",
      "Epoch 600, Loss: 0.6684\n",
      "Epoch 700, Loss: 0.6674\n",
      "Epoch 800, Loss: 0.6663\n",
      "Epoch 900, Loss: 0.6653\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Data\n",
    "torch.manual_seed(42)\n",
    "X = torch.randn(100, 3)\n",
    "y = (torch.rand(100, 1) > 0.5).float()\n",
    "\n",
    "# Model using nn.Sequential (simplifies construction)\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(3, 4),  # input → hidden\n",
    "    nn.ReLU(),        # activation\n",
    "    nn.Linear(4, 1),  # hidden → output\n",
    "    nn.Sigmoid()      # sigmoid activation\n",
    ")\n",
    "\n",
    "# Loss and optimizer\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(1000):\n",
    "    y_pred = model(X)\n",
    "    loss = loss_fn(y_pred, y)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99706443-7747-4ae1-8595-98a64a06e6ba",
   "metadata": {},
   "source": [
    "# [Extension] Multi-class Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82fe8a6-d3ac-442a-8f42-3aebdb4c5a0c",
   "metadata": {},
   "source": [
    "## [Numpy] Multiclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f72f1878-fb8f-4771-a41f-3337d815bdfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 2.3151, Accuracy: 0.25\n",
      "Epoch 100, Loss: 1.4549, Accuracy: 0.33\n",
      "Epoch 200, Loss: 1.2082, Accuracy: 0.38\n",
      "Epoch 300, Loss: 1.1233, Accuracy: 0.40\n",
      "Epoch 400, Loss: 1.0905, Accuracy: 0.40\n",
      "Epoch 500, Loss: 1.0750, Accuracy: 0.42\n",
      "Epoch 600, Loss: 1.0656, Accuracy: 0.39\n",
      "Epoch 700, Loss: 1.0588, Accuracy: 0.38\n",
      "Epoch 800, Loss: 1.0533, Accuracy: 0.38\n",
      "Epoch 900, Loss: 1.0484, Accuracy: 0.38\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Set seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# --- Data Preparation ---\n",
    "num_samples = 100     # Number of data points\n",
    "input_dim = 3         # Features\n",
    "hidden_dim = 4        # Hidden neurons\n",
    "num_classes = 3       # Number of classes\n",
    "\n",
    "# Random input data: shape (100, 3)\n",
    "X = torch.randn(num_samples, input_dim)\n",
    "\n",
    "# Random integer labels: shape (100,) with values {0, 1, 2}\n",
    "y = torch.randint(0, num_classes, (num_samples,))\n",
    "\n",
    "# --- Weight Initialization ---\n",
    "# Input → Hidden\n",
    "W1 = torch.randn(input_dim, hidden_dim, requires_grad=True)   # (3, 4)\n",
    "b1 = torch.zeros(hidden_dim, requires_grad=True)              # (4,)\n",
    "\n",
    "# Hidden → Output\n",
    "W2 = torch.randn(hidden_dim, num_classes, requires_grad=True) # (4, 3)\n",
    "b2 = torch.zeros(num_classes, requires_grad=True)             # (3,)\n",
    "\n",
    "# --- Training Loop ---\n",
    "lr = 0.01\n",
    "for epoch in range(1000):\n",
    "\n",
    "    # ----- Forward Pass -----\n",
    "    z1 = X @ W1 + b1          # (100, 4), Linear transformation\n",
    "    a1 = F.relu(z1)           # (100, 4), Apply ReLU activation\n",
    "\n",
    "    z2 = a1 @ W2 + b2         # (100, 3), Output logits for each class\n",
    "    y_pred = F.log_softmax(z2, dim=1)  # (100, 3), log-probabilities via softmax\n",
    "\n",
    "    # ----- Loss -----\n",
    "    # Negative log-likelihood loss using class indices\n",
    "    loss = F.nll_loss(y_pred, y)\n",
    "\n",
    "    # ----- Backward Pass -----\n",
    "    loss.backward()\n",
    "\n",
    "    # ----- Parameter Updates -----\n",
    "    with torch.no_grad():\n",
    "        W1 -= lr * W1.grad\n",
    "        b1 -= lr * b1.grad\n",
    "        W2 -= lr * W2.grad\n",
    "        b2 -= lr * b2.grad\n",
    "\n",
    "        # Zero gradients for next step\n",
    "        W1.grad.zero_()\n",
    "        b1.grad.zero_()\n",
    "        W2.grad.zero_()\n",
    "        b2.grad.zero_()\n",
    "\n",
    "    # ----- Monitoring -----\n",
    "    if epoch % 100 == 0:\n",
    "        pred_classes = torch.argmax(y_pred, dim=1)         # (100,)\n",
    "        accuracy = (pred_classes == y).float().mean()      # Compute accuracy\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}, Accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd50140-6914-4636-9df6-12d93577029a",
   "metadata": {},
   "source": [
    "## [PyTorch] Multiclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "158a103f-f039-460c-b08c-4c4b7853f982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 2.3151, Accuracy: 0.25\n",
      "Epoch 100, Loss: 1.4549, Accuracy: 0.33\n",
      "Epoch 200, Loss: 1.2082, Accuracy: 0.38\n",
      "Epoch 300, Loss: 1.1233, Accuracy: 0.40\n",
      "Epoch 400, Loss: 1.0905, Accuracy: 0.40\n",
      "Epoch 500, Loss: 1.0750, Accuracy: 0.42\n",
      "Epoch 600, Loss: 1.0656, Accuracy: 0.39\n",
      "Epoch 700, Loss: 1.0588, Accuracy: 0.38\n",
      "Epoch 800, Loss: 1.0533, Accuracy: 0.38\n",
      "Epoch 900, Loss: 1.0484, Accuracy: 0.38\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# -----------------------------\n",
    "# Data Preparation\n",
    "# -----------------------------\n",
    "num_samples = 100\n",
    "input_dim = 3\n",
    "hidden_dim = 4\n",
    "num_classes = 3\n",
    "\n",
    "# Input features: shape (100, 3)\n",
    "X = torch.randn(num_samples, input_dim)\n",
    "\n",
    "# Integer class labels: shape (100,)\n",
    "y = torch.randint(0, num_classes, (num_samples,))\n",
    "\n",
    "# -----------------------------\n",
    "# Manual Parameter Initialization\n",
    "# -----------------------------\n",
    "# Input → Hidden\n",
    "W1 = torch.randn(input_dim, hidden_dim, requires_grad=True)  # (3, 4)\n",
    "b1 = torch.zeros(hidden_dim, requires_grad=True)             # (4,)\n",
    "\n",
    "# Hidden → Output (now outputting num_classes logits)\n",
    "W2 = torch.randn(hidden_dim, num_classes, requires_grad=True)  # (4, 3)\n",
    "b2 = torch.zeros(num_classes, requires_grad=True)              # (3,)\n",
    "\n",
    "# -----------------------------\n",
    "# Training Loop\n",
    "# -----------------------------\n",
    "lr = 0.01\n",
    "for epoch in range(1000):\n",
    "    # ----- Forward Pass -----\n",
    "    z1 = X @ W1 + b1         # (100, 4) → Linear transform\n",
    "    a1 = F.relu(z1)          # (100, 4) → Nonlinear activation\n",
    "\n",
    "    z2 = a1 @ W2 + b2        # (100, 3) → Output logits\n",
    "    y_log_probs = F.log_softmax(z2, dim=1)  # (100, 3)\n",
    "\n",
    "    # ----- Loss -----\n",
    "    # Negative Log-Likelihood Loss (log_softmax + class labels)\n",
    "    loss = F.nll_loss(y_log_probs, y)\n",
    "\n",
    "    # ----- Backward Pass -----\n",
    "    loss.backward()\n",
    "\n",
    "    # ----- Weight Update -----\n",
    "    with torch.no_grad():\n",
    "        W1 -= lr * W1.grad\n",
    "        b1 -= lr * b1.grad\n",
    "        W2 -= lr * W2.grad\n",
    "        b2 -= lr * b2.grad\n",
    "\n",
    "        # Clear gradients\n",
    "        W1.grad.zero_()\n",
    "        b1.grad.zero_()\n",
    "        W2.grad.zero_()\n",
    "        b2.grad.zero_()\n",
    "\n",
    "    # ----- Logging -----\n",
    "    if epoch % 100 == 0:\n",
    "        # Get predicted class via argmax over log-probs\n",
    "        predictions = torch.argmax(y_log_probs, dim=1)\n",
    "        accuracy = (predictions == y).float().mean()\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}, Accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410cebb7-7e2d-46c9-ada6-eff799197811",
   "metadata": {},
   "source": [
    "## [Multiclass code using `nn.Module`]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f2880ee-a64c-4bdd-9f7b-7e6d1d07330a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 1.1444, Accuracy: 0.36\n",
      "Epoch 100, Loss: 1.0886, Accuracy: 0.40\n",
      "Epoch 200, Loss: 1.0669, Accuracy: 0.43\n",
      "Epoch 300, Loss: 1.0584, Accuracy: 0.40\n",
      "Epoch 400, Loss: 1.0547, Accuracy: 0.40\n",
      "Epoch 500, Loss: 1.0527, Accuracy: 0.41\n",
      "Epoch 600, Loss: 1.0512, Accuracy: 0.42\n",
      "Epoch 700, Loss: 1.0499, Accuracy: 0.42\n",
      "Epoch 800, Loss: 1.0487, Accuracy: 0.42\n",
      "Epoch 900, Loss: 1.0474, Accuracy: 0.42\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# -----------------------------\n",
    "# Data Preparation\n",
    "# -----------------------------\n",
    "num_samples = 100\n",
    "input_dim = 3\n",
    "hidden_dim = 4\n",
    "num_classes = 3\n",
    "\n",
    "# Input features: (100, 3)\n",
    "X = torch.randn(num_samples, input_dim)\n",
    "\n",
    "# Integer class labels: (100,) with values in {0, 1, 2}\n",
    "y = torch.randint(0, num_classes, (num_samples,))\n",
    "\n",
    "# -----------------------------\n",
    "# Define MLP using nn.Module\n",
    "# -----------------------------\n",
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(MLPClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)  # Input → Hidden\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size) # Hidden → Output\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))        # Apply ReLU after first layer\n",
    "        x = self.fc2(x)                # No softmax here!\n",
    "        return x                       # Return raw logits\n",
    "\n",
    "# Instantiate model\n",
    "model = MLPClassifier(input_dim, hidden_dim, num_classes)\n",
    "\n",
    "# -----------------------------\n",
    "# Loss Function + Optimizer\n",
    "# -----------------------------\n",
    "criterion = nn.CrossEntropyLoss()          # Combines LogSoftmax + NLLLoss\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# -----------------------------\n",
    "# Training Loop\n",
    "# -----------------------------\n",
    "for epoch in range(1000):\n",
    "    logits = model(X)                      # Forward pass → raw logits\n",
    "    loss = criterion(logits, y)            # Cross-entropy between logits & targets\n",
    "\n",
    "    optimizer.zero_grad()                  # Reset gradients\n",
    "    loss.backward()                        # Backpropagation\n",
    "    optimizer.step()                       # Update weights\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        predictions = torch.argmax(logits, dim=1)\n",
    "        accuracy = (predictions == y).float().mean()\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}, Accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a1a5cd-901f-493c-90bc-b4906f464c0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5e9af7-b531-4c8b-8bdb-aeec90a34606",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4e58b5-067b-418f-8600-b369de07ca10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
